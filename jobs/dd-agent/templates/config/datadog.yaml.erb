# The host of the Datadog intake server to send Agent data to
dd_url: <%= p("dd.url", "https://app.datadoghq.com") %>

# The Datadog api key to associate your Agent's data with your organization.
# Can be found here:
# https://app.datadoghq.com/account/settings
api_key: <%= p('dd.api_key') %>

# If you need a proxy to connect to the Internet, provide it here (default:
# disabled). You can use the 'no_proxy' list to specify hosts that should bypass the
# proxy. These settings might impact your checks requests, please refer to the
# specific check documentation for more details.

# Only use a proxy if one is set
<% if p("dd.proxy.http", false) || p("dd.proxy.https", false) || p("dd.proxy.no_proxy", false) %>
proxy:
  <% if_p("dd.proxy.http") do |http| %>
  http: <%= http %>
  <% end %>
  <% if_p("dd.proxy.https") do |https| %>
  https: <%= https %>
  <% end %>
  <% if_p("dd.proxy.no_proxy") do |no_proxy| %>
  <%
    # check to see if no_proxy has been set as a string
    if no_proxy.class == String
      no_proxy = no_proxy.split(",")
    end
  %>
  no_proxy:
    <% no_proxy.each do |no_proxy| %>
    - <%= no_proxy %>
    <% end %>
  <% end %>
<% end %>

# Setting this option to "yes" will tell the agent to skip validation of SSL/TLS certificates.
# This may be necessary if the agent is running behind a proxy. See this page for details:
# https://github.com/DataDog/dd-agent/wiki/Proxy-Configuration#using-haproxy-as-a-proxy
skip_ssl_validation: <%= p("dd.skip_ssl_validation", "no") %>

# Force the hostname to whatever you want. (default: auto-detected)
<% if_p("dd.hostname") do |hostname| %>
hostname: <%= hostname %>
<% end.else do %>
<% if_p("dd.use_uuid_hostname") do |hostname| %>
hostname: <%= hostname %>
<% end.else do %>
hostname: <%= spec.name.tr('_', '-') %>-<%= spec.index %>
<% end %>
<% end %>

cloud_foundry: true
<% if spec.id and not spec.id.empty? %>
bosh_id: <%= spec.id %>
<% end %>

# Set the host's tags
<%
generated_tags = {}
if p('dd.bosh_tags') == true || p('dd.bosh_tags') =~ (/(true|t|yes|y|1)$/i)
    bosh_tags_prefix=p('dd.bosh_tags_prefix', 'bosh_')
    generated_tags["#{bosh_tags_prefix}id"] = spec.id if spec.id and not spec.id.empty?
    generated_tags["#{bosh_tags_prefix}job"] = spec.name if spec.name and not spec.name.empty?
    generated_tags["#{bosh_tags_prefix}index"] = spec.index if spec.index
    generated_tags["#{bosh_tags_prefix}az"] = spec.az if spec.az and not spec.az.empty?
    generated_tags["#{bosh_tags_prefix}deployment"] = spec.deployment if spec.deployment and not spec.deployment.empty?
    generated_tags["#{bosh_tags_prefix}name"] = spec.name if spec.name and not spec.name.empty?
    generated_tags["#{bosh_tags_prefix}address"] = spec.address if spec.address and not spec.address.empty?
    generated_tags["#{bosh_tags_prefix}ip"] = spec.ip if spec.ip and not spec.ip.empty?
end
# The others are optional, however this one is not, as it figures into our dashboard
generated_tags["bosh_deployment"] = spec.deployment if spec.deployment and not spec.deployment.empty?
generated_tags["deployment"] = spec.deployment if spec.deployment and not spec.deployment.empty?

# Since YAML allows making arrays as arrays, it should be an option here, too
# However, the tile has no good option to make an array, so there it is a string
tags = p("dd.tags", "")
if tags.class == String
  tags = tags.split(",")
end
tags = tags + generated_tags.map { |k, v| "#{k}:#{v}" }

# The firehose nozzle uses this tag, which is frustrating, but we want the data to be able to conform
tags += ["index:#{spec.id}"] if spec.id and not spec.id.empty?
tags += ["ip:#{spec.ip}"] if spec.ip and not spec.ip.empty?
tags += ["cloudfoundry"]
%>
tags:
  <% tags.each do |tag| %>
  - <%= tag %>
  <% end %>

# Histogram and Historate configuration
#
# Configure which aggregated value to compute. Possible values are: min, max,
# median, avg, sum and count.
#
#
# Configure which percentiles will be computed. Must be a list of float
# between 0 and 1.
# Warning: percentiles must be specified as yaml strings
#
histogram_aggregates: <%= p("dd.histogram_aggregates", ["max", "median", "avg", "count"]).join(', ') %>
histogram_percentiles: <%= p("dd.histogram_percentiles", ["0.95"]).join(', ') %>

# Forwarder timeout in seconds
# forwarder_timeout: 20

# The forwarder retries failed requests. Use this setting to change the
# maximum length of the forwarder's retry queue (each request in the queue
# takes no more than 2MB in memory)
# forwarder_retry_queue_max_size: 30

# The number of workers used by the forwarder. Please note each worker will
# open an outbound HTTP connection towards Datadog's metrics intake at every
# flush.
forwarder_num_workers: <%= p('log_format_json', 1) %>

# Set this option to "yes" to output logs in JSON format
log_format_json: <%= p('forwarder_num_workers', "no") %>

# Collect AWS EC2 custom tags as agent tags (requires an IAM role associated with the instance)
collect_ec2_tags: <%= p("dd.collect_ec2_tags", "no") %>

# Incorporate security-groups into tags collected from AWS EC2
collect_security_groups: <%= p("dd.collect_security_groups", "no") %>

# The path containing check configuration files
# By default, uses the conf.d folder located in the agent configuration folder.
# confd_path:

# The path containing check configuration files
# By default, uses the conf.d folder located in the agent configuration folder.
# confd_path:

# Additional path where to search for Python checks
# By default, uses the checks.d folder located in the agent configuration folder.
# additional_checksd:

# The port for the go_expvar server
expvar_port: <%= p('dd.expvar_port', 15000) %>
# The port on which the IPC api listens
cmd_port: <%= p('dd.cmd_port', 15001) %>

# The port for the browser GUI to be served
# Setting 'GUI_port: -1' turns off the GUI completely
# Default is '5002' on Windows and macOS ; turned off on Linux
# GUI_port: -1

# The Agent runs workers in parallel to execute checks. By default the number
# of workers is set to 1. If set to 0 the agent will automatically determine
# the best number of runners needed based on the number of checks running. This
# would optimize the check collection time but may produce CPU spikes.
check_runners: <%= p('dd.check_runners', 1) %>

# Metadata collection should always be enabled, except if you are running several
# agents/dsd instances per host. In that case, only one agent should have it on.
# WARNING: disabling it on every agent will lead to display and billing issues
<% if p('dd.enable_metadata_collection') == true || p('dd.enable_metadata_collection') =~ (/(true|t|yes|y|1)$/i) %>
enable_metadata_collection: yes
<% else %>
enable_metadata_collection: no
<% end %>


# Enable the gohai collection of systems data
enable_gohai: <%= p('dd.enable_gohai', 'yes') %>

# IPC api server timeout in seconds
# server_timeout: 15

# Metadata providers, add or remove from the list to enable or disable collection.
# Intervals are expressed in seconds. You can also set a provider's interval to 0
# to disable it.
# metadata_providers:
#  - name: k8s
#    interval: 60

# DogStatsd
#
# If you don't want to enable the DogStatsd server, set this option to no
<% if p('dd.use_dogstatsd') == true || p('dd.use_dogstatsd') =~ (/(true|t|yes|y|1)$/i) %>
use_dogstatsd: yes
<% else %>
use_dogstatsd: no
<% end %>
#
# Make sure your client is sending to the same UDP port
dogstatsd_port: <%= p("dd.dogstatsd_port", "18125") %>
#
# Whether dogstatsd should listen to a Unix Socket instead of UDP (*nix only).
# Set to a valid filesystem path to enable
# dogstatsd_socket:
#
# Whether origin detection and container tagging should be enabled for Unix
# Socket incoming metrics. This feature is experimental for now.
#
# dogstatsd_origin_detection: false
#
# The buffer size use to receive statsd packet, in bytes
# dogstatsd_buffer_size: 1024
#
# Whether dogstatsd should listen to non local UDP traffic
dogstatsd_non_local_traffic: <%= p("dd.non_local_traffic", "no") %>
#
# Publish dogstatsd's internal stats as Go epxvars
# dogstatsd_stats_enable: no
#
# How many items in the dogstatsd's stats circular buffer
# dogstatsd_stats_buffer: 10
#
# The port for the go_expvar server
# dogstatsd_stats_port: 5000

# Logs agent
#
# Logs agent is disabled by default
# log_enabled: false

# JMX
#
# jmx_pipe_path:
# jmx_pipe_name: dd-auto_discovery

# Autoconfig
#
# Directory containing configuration templates
# autoconf_template_dir: /datadog/check_configs
#
# The providers the Agent should call to collect checks configurations.
# Please note the File Configuration Provider is enabled by default and cannot
# be configured.
# config_providers:

## The kubelet provider handles templates embedded in pod annotations, see
## https://docs.datadoghq.com/guides/autodiscovery/#template-source-kubernetes-pod-annotations
#   - name: kubelet
#     polling: true

## The docker provider handles templates embedded in container labels, see
## https://docs.datadoghq.com/guides/autodiscovery/#template-source-docker-label-annotations
#   - name: docker
#     polling: true

#   - name: etcd
#     polling: true
#     template_dir: /datadog/check_configs
#     template_url: http://127.0.0.1
#     username:
#     password:

#   - name: consul
#     polling: true
#     template_dir: /datadog/check_configs
#     template_url: http://127.0.0.1
#     ca_file:
#     ca_path:
#     cert_file:
#     key_file:
#     username:
#     password:
#     token:

#   - name: zookeeper
#     polling: true
#     template_dir: /datadog/check_configs
#     template_url: 127.0.0.1
#     username:
#     password:

# Logging
#
log_level: <%= p("dd.log_level", "INFO") %>
log_file: /var/vcap/sys/log/dd-agent/agent.log

# Set the auth token
auth_token_file_path: /var/vcap/sys/run/dd-agent/auth_token

# Autodiscovery
#
# Change the root directory to look at to get cgroup statistics. Useful when running inside a
# container with host directories mounted on a different folder.
# Default if environment variable "DOCKER_DD_AGENT" is set to "yes"
# "/host/sys/fs/cgroup" and "/sys/fs/cgroup" if not.
#
# container_cgroup_root: /host/sys/fs/cgroup/
#
# Change the root directory to look at to get proc statistics. Useful when running inside a
# container with host directories mounted on a different folder.
# Default if environment variable "DOCKER_DD_AGENT" is set to "yes"
# "/host/proc" and "/proc" if not.
#
# container_proc_root: /host/proc
#
# Choose "auto" if you want to let the agent find any relevant listener on your host
# At the moment, the only auto listener supported is docker
# If you have already set docker anywhere in the listeners, the auto listener is ignored
# listeners:
#   - name: auto
#   - name: docker
#
# Exclude containers based on their name or image
# An excluded container will not get any individual container metric reported for it.
# However it will still appear in the container count since ignoring it here would give
# a wrong impression about the docker daemon load.
#
# How it works: exclude first.
# If a container matches an exclude rule, it won't be included unless it also matches an include rule.
#
# Rules are regexp.
#
# Examples:
# exclude all, except containers based on the 'ubuntu' image or the 'debian' image.
# ac_exclude: ["image:.*"]
# ac_include: ["image:ubuntu", "image:debian"]
#
# include all, except containers based on the 'ubuntu' image.
# ac_exclude: ["image:ubuntu"]
# ac_include: []
#
# exclude all debian images except containers with a name starting with 'frontend'.
# ac_exclude: ["image:debian"]
# ac_include: ["name:frontend.*"]
#
# ac_exclude: []
# ac_include: []
#
#
# Exclude default pause containers from orchestrators.
#
# By default the agent will not monitor kubernetes/openshift pause
# container. They will still be counted in the container count (just like
# excluded containers) since ignoring them would give a wrong impression
# about the docker daemon load.
#
# exclude_pause_container: true

# Docker tag extraction
#
# We can extract container label or environment variables
# as metric tags. If you prefix your tag name with +, it
# will only be added to high cardinality metrics (docker check)
#
# docker_labels_as_tags:
#   label_name:                  tag_name
#   high_cardinality_label_name: +tag_name
# docker_env_as_tags:
#   ENVVAR_NAME: tag_name
#
# Example:
# docker_labels_as_tags:
#   com.docker.compose.service: service_name
#   com.docker.compose.project: +project_name
#

# Kubernetes tag extraction
#
# We can extract pod labels as metric tags. If you prefix your
# tag name with +, it will only be added to high cardinality metrics
#
# kubernetes_pod_labels_as_tags:
#   app:               kube_app
#   pod-template-hash: +kube_pod-template-hash
#

# ECS integration
#
# URL where the ECS agent can be found. Standard cases will be autodetected.
# ecs_agent_url: http://localhost:51678
#

# Process agent specific settings
#
process_config:
#   Note: the Process Agent expects this to be a string
<% if p('dd.process_agent_enabled', false) == true || p('dd.process_agent_enabled', false) =~ (/(true|t|yes|y|1)$/i) %>
  enabled: true
<% end %>
#   The full path to the file where process-agent logs will be written.
  log_file: /var/vcap/sys/log/dd-agent/process_agent.log
#   The interval, in seconds, at which we will run each check. If you want consistent
#   behavior between real-time you may set the Container/ProcessRT intervals to 10.
#   Defaults to 10s for normal checks and 2s for others.
#   intervals:
#     container:
#     container_realtime:
#     process:
#     process_realtime:
#   A list of regex patterns that will exclude a process if matched.
#   blacklist_patterns:
#   How many check results to buffer in memory when POST fails. The default is usually fine.
#   queue_size:
#   The maximum number of file descriptors to open when collecting net connections.
#   Only change if you are running out of file descriptors from the Agent.
#   max_proc_fds:
#   The maximum number of processes or containers per message.
#   Only change if the defaults are causing issues.
#   max_per_message:
#   Overrides the path to the Agent bin used for getting the hostname. The default is usually fine.
#   dd_agent_bin:
#   Overrides of the environment we pass to fetch the hostname. The default is usually fine.
#   dd_agent_env:

# Trace Agent Specific Settings
#
# apm_config:
#   Whether or not the APM Agent should run
#   enabled: true
#   The environment tag that Traces should be tagged with
#   Will inherit from "env" tag if none is applied here
#   env: none
#   The port that the Receiver should listen on
#   receiver_port: 8126
#   Whether the Trace Agent should listen for non local traffic
#   Only enable if Traces are being sent to this Agent from another host/container
#   apm_non_local_traffic: false
#   Extra global sample rate to apply on all the traces
#   This sample rate is combined to the sample rate from the sampler logic, still promoting interesting traces
#   From 1 (no extra rate) to 0 (don't sample at all)
#   extra_sample_rate: 1.0
#   Maximum number of traces per second to sample.
#   The limit is applied over an average over a few minutes ; much bigger spikes are possible.
#   Set to 0 to disable the limit.
#   max_traces_per_second: 10
#   A blacklist of regular expressions can be provided to disable certain traces based on their resource name
#   all entries must be surrounded by double quotes and separated by commas
#   Example: ["(GET|POST) /healthcheck", "GET /V1"]
#   ignore_resources: []

<%
  agent_config = p('dd.agent_config', {})
  if agent_config.class == String
    agent_config = JSON.load(agent_config)
  end

  agent_config.each do |key, value|
%>
<%= key %>: <%= JSON.dump(value) %>
<% end %>
