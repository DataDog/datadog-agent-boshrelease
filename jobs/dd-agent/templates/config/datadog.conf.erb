[Main]

# The host of the Datadog intake server to send Agent data to
dd_url: <%= p("dd.url", "https://app.datadoghq.com") %>

# If you need a proxy to connect to the Internet, provide the settings here
<% if_p('dd.proxy') do |proxy| %>
proxy_host: <%= proxy["host"] %>
proxy_port: <%= proxy["port"] %>
<% if_p('dd.proxy.user') do |user| %>proxy_user: <%= user %><% end %>
<% if_p('dd.proxy.password') do |pass| %>proxy_password: <%= pass %><% end %>
# To be used with some proxys that return a 302 which make curl switch from POST to GET
# See http://stackoverflow.com/questions/8156073/curl-violate-rfc-2616-10-3-2-and-switch-from-post-to-get
# proxy_forbid_method_switch: no
<% end %>

# If you run the agent behind haproxy, you might want to set this to yes
skip_ssl_validation: <%= p("dd.skip_ssl_validation", "no") %>

# The Datadog api key to associate your Agent's data with your organization.
# Can be found here: https://app.datadoghq.com/account/settings
api_key: <%= p('dd.api_key') %>

<%
  # Force the hostname to whatever you want. (default: auto-detected)
  # if no hostname is specified, it will just use the name of the VM
  if p("dd.hostname", nil)
    hostname = p("dd.hostname", "")
  elsif p("dd.friendly_hostname", true)
    hostname = "#{spec.name.tr('_', '-')}-#{spec.index}"
  elsif p("dd.use_uuid_hostname", false) and spec.id and not spec.id.empty?
    hostname = spec.id
  end
%>

hostname: <%= hostname %>


cloud_foundry: true
<% if spec.id and not spec.id.empty? %>
bosh_id: <%= spec.id %>
<% end %>

enable_gohai: <%= p('dd.enable_gohai', 'yes') %>

# Set the host's tags
<%
generated_tags = {}
if p('dd.bosh_tags') == true || p('dd.bosh_tags') =~ (/(true|t|yes|y|1)$/i)
    bosh_tags_prefix=p('dd.bosh_tags_prefix', 'bosh_')
    generated_tags["#{bosh_tags_prefix}id"] = spec.id if spec.id and not spec.id.empty?
    generated_tags["#{bosh_tags_prefix}job"] = spec.name if spec.name and not spec.name.empty?
    generated_tags["#{bosh_tags_prefix}index"] = spec.index if spec.index
    generated_tags["#{bosh_tags_prefix}az"] = spec.az if spec.az and not spec.az.empty?
    generated_tags["#{bosh_tags_prefix}deployment"] = spec.deployment if spec.deployment and not spec.deployment.empty?
    generated_tags["#{bosh_tags_prefix}name"] = spec.name if spec.name and not spec.name.empty?

    if p('dd.address_tag')
      generated_tags["#{bosh_tags_prefix}address"] = spec.address if spec.address and not spec.address.empty?
    end
    if p('dd.ip_tag')
      generated_tags["#{bosh_tags_prefix}ip"] = spec.ip if spec.ip and not spec.ip.empty?
    end
end
# The others are optional, however this one is not, as it figures into our dashboard
generated_tags["bosh_deployment"] = spec.deployment if spec.deployment and not spec.deployment.empty?
generated_tags["deployment"] = spec.deployment if spec.deployment and not spec.deployment.empty?

custom_tags = []
if p('dd.tags', []).class == String
  custom_tags = p('dd.tags', "").split(",")
else
  custom_tags = p('dd.tags', [])
end

tags = custom_tags
tags += generated_tags.map { |k, v| "#{k}:#{v}" }
# The firehose nozzle uses this tag, which is frustrating, but we want the data to be able to conform
tags += ["index:#{spec.id}"] if spec.id and not spec.id.empty?
if p('dd.ip_tag')
  tags += ["ip:#{spec.ip}"] if spec.ip and not spec.ip.empty?
end
tags += ["cloudfoundry"]
%>
tags: <%= tags.join(', ') %>

# Add one "dd_check:checkname" tag per running check. It makes it possible to slice
# and dice per monitored app (= running Agent Check) on Datadog's backend.
create_dd_check_tags: <%= p("dd.create_dd_check_tags", "no") %>

# Collect AWS EC2 custom tags as agent tags (requires an IAM role associated with the instance)
collect_ec2_tags: <%= p("dd.collect_ec2_tags", "no") %>

# Incorporate security-groups into tags collected from AWS EC2
collect_security_groups: <%= p("dd.collect_security_groups", "no") %>

# Enable Agent Developer Mode
# Agent Developer Mode collects and sends more fine-grained metrics about agent and check performance
# developer_mode: no
# In developer mode, the number of runs to be included in a single collector profile
# collector_profile_interval: 20

# use unique hostname for GCE hosts, see http://dtdg.co/1eAynZk
gce_updated_hostname: <%= p("dd.gce_updated_hostname", "yes") %>

# Set the threshold for accepting points to allow anything
# with recent_point_threshold seconds
# Defaults to 30 seconds if no value is provided
# recent_point_threshold: 30

# Change port the Agent is listening to
listen_port: <%= p("dd.listen_port", "17123") %>

<% if p('dd.use_graphite') == true || p('dd.use_graphite') =~ (/(true|t|yes|y|1)$/i) %>
# Start a graphite listener on this port
graphite_listen_port: <%= p("dd.graphite_listen_port", "17124") %>
<% end %>

# Additional directory to look for Datadog checks
additional_checksd: /var/vcap/jobs/dd-agent/packages/dd-agent/checks.d/

# Allow non-local traffic to this Agent
# This is required when using this Agent as a proxy for other Agents
# that might not have an internet connection
# For more information, please see
# https://github.com/DataDog/dd-agent/wiki/Network-Traffic-and-Proxy-Configuration
non_local_traffic: <%= p("dd.non_local_traffic", "no") %>

# Select the Tornado HTTP Client in the forwarder
# Default to the simple http client
# use_curl_http_client: False

# The loopback address the Forwarder and Dogstatsd will bind.
# Optional, it is mainly used when running the agent on Openshift
# bind_host: localhost

# If enabled the collector will capture a metric for check run times.
check_timings: <%= p("dd.check_timings", "no") %>

# If you want to remove the 'ww' flag from ps catching the arguments of processes
# for instance for security reasons
exclude_process_args: <%= p("dd.exclude_process_args", "no") %>

histogram_aggregates: <%= p("dd.histogram_aggregates", ["max", "median", "avg", "count"]).join(', ') %>
histogram_percentiles: <%= p("dd.histogram_percentiles", ["0.95"]).join(', ') %>


# ========================================================================== #
# Service Discovery                                                          #
# See https://github.com/DataDog/dd-agent/wiki/Service-Discovery for details #
# ========================================================================== #
#
# Service discovery allows the agent to look for running services
# and load a configuration object for the one it recognizes.
# This feature is disabled by default.
# Uncomment this line to enable it (works for docker containers only for now).
# service_discovery_backend: docker
#
# Define which key/value store must be used to look for configuration templates.
# Default is etcd. Consul is also supported.
# sd_config_backend: etcd
#
# Settings for connecting to the service discovery backend.
# sd_backend_host: 127.0.0.1
# sd_backend_port: 4001
#
# By default, the agent will look for the configuration templates under the
# `/datadog/check_configs` key in the back-end. If you wish otherwise, uncomment this option
# and modify its value.
# sd_template_dir: /datadog/check_configs


# ========================================================================== #
# DogStatsd configuration                                                    #
# ========================================================================== #

# If you don't want to enable the DogStatsd server, set this option to no
<% if p('dd.use_dogstatsd') == true || p('dd.use_dogstatsd') =~ (/(true|t|yes|y|1)$/i) %>
use_dogstatsd: yes
<% else %>
use_dogstatsd: no
<% end %>

# DogStatsd is a small server that aggregates your custom app metrics. For
# usage information, check out http://docs.datadoghq.com/guides/dogstatsd/

# Make sure your client is sending to the same port.
# 8125 is frequently used for cloud foundry's own statsd stuff. We need to use a different port.
dogstatsd_port: <%= p("dd.dogstatsd_port", "18125") %>

# By default dogstatsd will post aggregate metrics to the Agent (which handles
# errors/timeouts/retries/etc). To send directly to the datadog api, set this
# to https://app.datadoghq.com.
<% if_p("dd.dogstatsd_target") do |target| %>
dogstatsd_target : <%= target %>
<% end.else do %>
dogstatsd_target: http://127.0.0.1:<%= p("dd.listen_port", "17123") %>
<% end %>

# If you want to forward every packet received by the dogstatsd server
# to another statsd server, uncomment these lines.
# WARNING: Make sure that forwarded packets are regular statsd packets and not "dogstatsd" packets,
# as your other statsd server might not be able to handle them.
<% if_p("dd.statsd_forward_host") do |statsd| %>
statsd_forward_host: <%= statsd %>
statsd_forward_port: <%= p("dd.statsd_forward_port", "8125") %>
<% end %>

# you may want all statsd metrics coming from this host to be namespaced
# in some way; if so, configure your namespace here. a metric that looks
# like `metric.name` will instead become `namespace.metric.name`
# statsd_metric_namespace:
<% if_p("dd.statsd_metric_namespace") do |statsd_ns| %>
statsd_metric_namespace: <%= statsd_ns %>
<% end %>

# By default, dogstatsd supports only plain ASCII packets. However, most
# (dog)statsd client support UTF8 by encoding packets before sending them
# this option enables UTF8 decoding in case you need it.
# However, it comes with a performance overhead of ~10% in the dogstatsd
# server. This will be taken care of properly in the new gen agent core.
utf8_decoding: <%= p("dd.utf8_decoding", "no") %>


<% if p('dd.use_ganglia') == true || p('dd.use_ganglia') =~ (/(true|t|yes|y|1)$/i) %>
# ========================================================================== #
# Service-specific configuration                                             #
# ========================================================================== #

# -------------------------------------------------------------------------- #
#   Ganglia                                                                  #
# -------------------------------------------------------------------------- #

# Ganglia host where gmetad is running
ganglia_host: <%= p("dd.ganglia_host", "localhost") %>
# Ganglia port where gmetad is running
ganglia_port: <%= p("dd.ganglia_port", "8651") %>
<% end %>


<% if_p("dd.dogstreams") do |dogstreams| %>
# -------------------------------------------------------------------------- #
#  Dogstream (log file parser)
# -------------------------------------------------------------------------- #
#
# Comma-separated list of logs to parse and optionally custom parsers to use.
# The form should look like this:
#
#   dogstreams: /path/to/log1:parsers_module:custom_parser, /path/to/log2, /path/to/log3, ...
#
# Or this:
#
#   dogstreams: /path/to/log1:/path/to/my/parsers_module.py:custom_parser, /path/to/log2, /path/to/log3, ...
#
# Each entry is a path to a log file and optionally a Python module/function pair
# separated by colons.
#
# Custom parsers should take a 2 parameters, a logger object and
# a string parameter of the current line to parse. It should return a tuple of
# the form:
#   (metric (str), timestamp (unix timestamp), value (float), attributes (dict))
# where attributes should at least contain the key 'metric_type', specifying
# whether the given metric is a 'counter' or 'gauge'.
#
# Unless parsers are specified with an absolute path, the modules must exist in
# the Agent's PYTHONPATH. You can set this as an environment variable when
# starting the Agent. If the name of the custom parser function is not passed,
# 'parser' is assumed.
#
# If this value isn't specified, the default parser assumes this log format:
#     metric timestamp value key0=val0 key1=val1 ...
#
dogstreams: <%= dogstreams.join(', ') %>
<% end %>


<% if_p("dd.custom_emitters") do |custom_emitters| %>
# ========================================================================== #
# Custom Emitters                                                            #
# ========================================================================== #
#
# Comma-separated list of emitters to be used in addition to the standard one
#
# Expected to be passed as a comma-separated list of colon-delimited
# name/object pairs.
#
# custom_emitters: /usr/local/my-code/emitters/rabbitmq.py:RabbitMQEmitter
#
# If the name of the emitter function is not specified, 'emitter' is assumed.
custom_emitters: <%= custom_emitters.join(', ') %>
<% end %>

<% if p('dd.process_agent_enabled', false) == true || p('dd.process_agent_enabled', false) =~ (/(true|t|yes|y|1)$/i) %>
process_agent_enabled: true
<% end %>

# ========================================================================== #
# Logging
# ========================================================================== #
log_level: <%= p("dd.log_level", "INFO") %>

collector_log_file: /var/vcap/sys/log/dd-agent/collector.log
forwarder_log_file: /var/vcap/sys/log/dd-agent/forwarder.log
dogstatsd_log_file: /var/vcap/sys/log/dd-agent/dogstatsd.log
jmxfetch_log_file: /var/vcap/sys/log/dd-agent/jmxfetch.log

# if syslog is enabled but a host and port are not set, a local domain socket
# connection will be attempted
log_to_syslog: no
# syslog_host:
# syslog_port:

[process.config]
log_file: /var/vcap/sys/log/dd-agent/process_agent.log
